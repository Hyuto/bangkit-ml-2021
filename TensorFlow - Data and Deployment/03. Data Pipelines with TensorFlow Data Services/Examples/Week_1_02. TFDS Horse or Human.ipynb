{
 "cells": [
  {
   "source": [
    "# TFDS Horse or Human"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "• Using TensorFlow Version        : 2.3.1\n• Using TensorFlow Dataset Version: 4.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"\\u2022 Using TensorFlow Version        :\", tf.__version__)\n",
    "print(\"\\u2022 Using TensorFlow Dataset Version:\", tfds.__version__)"
   ]
  },
  {
   "source": [
    "**Local Additional Setup**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "def check_dir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "TEMP_DIR = 'tmp2'\n",
    "DATA_DIR = '../../dataset'\n",
    "\n",
    "check_dir(TEMP_DIR)\n",
    "check_dir(DATA_DIR)"
   ]
  },
  {
   "source": [
    "## Prepare `horses_or_humans` Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSq4t32ZHHpt"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ../../dataset\\horses_or_humans\\3.0.0...\u001b[0m\n",
      "\u001b[1mDataset horses_or_humans downloaded and prepared to ../../dataset\\horses_or_humans\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True, data_dir=DATA_DIR)\n",
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True, data_dir=DATA_DIR)\n",
    "\n",
    "train_batches = data.shuffle(100).batch(32)\n",
    "validation_batches = val_data.batch(32)"
   ]
  },
  {
   "source": [
    "## Create and Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 5s 141ms/step - loss: 7.7420 - accuracy: 0.6193 - val_loss: 0.2726 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 3s 99ms/step - loss: 0.1434 - accuracy: 0.9523 - val_loss: 0.5717 - val_accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 3s 99ms/step - loss: 0.0766 - accuracy: 0.9708 - val_loss: 0.8816 - val_accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 0.0484 - accuracy: 0.9834 - val_loss: 0.8526 - val_accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.3903 - val_accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.8947 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 3s 101ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.4350 - val_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 3s 102ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.9688\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 3.6833e-04 - accuracy: 1.0000 - val_loss: 0.8892 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 3s 98ms/step - loss: 2.2984e-04 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n",
    "                                      input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_batches, epochs=10, validation_data=validation_batches, validation_steps=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "horse-or-human.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
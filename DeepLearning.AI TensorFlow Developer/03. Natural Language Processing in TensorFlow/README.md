# Natural Language Processing in TensorFlow

## Notebook

* Week 1<br>
   1. [Tokenizer](Lesson/Week_1_01%20Tokenizer.ipynb)
   2. [Padding Sequences](Lesson/Week_1_02%20Padding%20Sequences.ipynb)
   3. [Try on Sarcasm Dataset](Lesson/Week_1_03%20Try%20on%20Sarcasm%20Dataset.ipynb)
   4. **Exercise** : [Explore the BBC news archive](Exercise/Week_1_Exercise_Explore%20the%20BBC%20news%20archive.ipynb)
* Week 2<br>
   1. [Lesson 1](Lesson/Week_2_01%20Lesson%201.ipynb)
   2. [Lesson 2](Lesson/Week_2_02%20Lesson%202.ipynb)
   3. [Subwords text encoder](Lesson/Week_2_03%20Subwords%20text%20encoder.ipynb)
   4. **Exercise** : [BBC news archive](Exercise/Week_2_Exercise_BBC%20news%20archive.ipynb)
* Week 3<br>
   1. [IMDB Subwords 8K with Single Layer LSTM](Lesson/Week_3_01%20IMDB%20Subwords%208K%20with%20Multi%20Layer%20LSTM.ipynb)
   2. [IMDB Subwords 8K with Multi Layer LSTM](Lesson/Week_3_02%20IMDB%20Subwords%208K%20with%20Single%20Layer%20LSTM.ipynb)
   3. [Sarcasm with Bidirectional LSTM](Lesson/Week_3_03%20Sarcasm%20with%201D%20Convolutional%20Layer.ipynb)
   4. [Sarcasm with 1D Convolutional Layer](Lesson/Week_3_04%20Sarcasm%20with%20Bidirectional%20LSTM.ipynb)
   5. **Exercise** : [Exploring overfitting in NLP](Exercise/Week_3_Exploring%20overfitting%20in%20NLP.ipynb)
* Week 4<br>
   1. [Lesson 1](Lesson/Week_4_01%20Lesson%201.ipynb)
   2. [Lesson 2](Lesson/Week_4_02%20Lesson%202.ipynb)
   3. **Exercise** : [Using LSTMs, see if you can write Shakespeare!](Exercise/Week_4_LSTM%20Shakespeare.ipynb)

## Quizz

1. [Quizz Week 1](./Assets/Week%201_Quizz.png)
2. [Quizz Week 2](./Assets/Week%202_Quizz.png)
3. [Quizz Week 4](./Assets/Week%203_Quizz.png)
4. [Quizz Week 4](./Assets/Week%204_Quizz.png)

## Note

1. Rishabh Misra : [News headlines dataset for sarcasm detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home)
2. [IMDB reviews dataset](http://ai.stanford.edu/~amaas/data/sentiment/)
3. [Tensorflow Dataset](https://www.tensorflow.org/datasets/catalog/overview)
4. Andrew NG : [Sequence Modeling Course](https://www.coursera.org/lecture/nlp-sequence-models/deep-rnns-ehs0S)
5. Andrew NG : [LSTM](https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay)